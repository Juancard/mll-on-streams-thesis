\chapter{Introducción}

En los últimos años ha habido un aumento considerable de datos de diversa índole y generados por fuentes heterogéneas. Según los autores \citeauthor{gantz_extracting_2011}, el volumen total de datos creados y replicados en el mundo durante el año 2011 supera los 1.8 ZB (zettabytes) y se ha estimado que duplica cada dos años \cite{gantz_extracting_2011}. Los avances en el área de tecnología de la información (IT) han contribuido a una continua producción de datos y expansión del campo digital, tal es el caso para la red social \textit{Facebook}, la cual recibe cada hora un flujo de 10 millones de fotos que publican sus usuarios \cite{mayer-schonberger_big_2013}. A estas grandes colecciones de datos se las conoce como \textit{big data} y acarrean nuevas oportunidades y desafíos al campo de las ciencias de la computación. En cuestiones económicas, un análisis a gran escala en búsqueda de tendencias en el comportamiento de los usuarios o clientes de un sistema puede dar una ventaja competitiva en el mercado y, en adición, proveer de un servicio valioso a la comunidad. Potencialmente, la ‘big data’ puede ser una fuente que proporcione a la comunidad de conocimiento nuevo sobre el mundo en el que habita, o como ha mencionado \citeauthor{fayyad_advances_1996} en su escrito sobre el descubrimiento de conocimiento, “Los datos que percibimos de nuestro ambiente son la evidencia básica que usamos para construir teorías y modelos sobre el universo en el que vivimos”\footnote{“Data we capture about our environment are the basic evidence we use to build theories and models of the universe we live in” \cite[p. 2]{fayyad_advances_1996}. Traducción propia.}.

\chapter{Experimentos y Resultados}
\todo{escribir intro de capitulo}

\section{Colecciones}


Se seleccionan colecciones de datos multi-etiquetas del mundo real que han sido
aplicados previamente en la literatura para evaluar la capacidad predictiva de
los modelos de clasificación \cite{osojnik_multi-label_2017, read_scalable_2012,
	buyukcakir_novel_2018}. La tabla \ref{tab:datasets} enumera sus características
principales, incluyendo métricas que describen su grado de multi-etiquetado (ver
sección \ref{mll_def_formal}). Una descripción detallada de cada una se lista a
continuación:

\begin{description}

	\item{20ng} \footnote{\url{https://www.uco.es/kdis/mllresources/}}: Es una
	      colección que consta de casi 20 mil publicaciones provenientes de grupos de
	      noticias y que abordan 20 tópicos diferentes \cite{lang_newsweeder_1995}.
	      La colección es de texto y fue preprocesada para formar 1006 atributos
	      numéricos.

	\item{Enron}
	      \footnote{\url{http://sourceforge.net/projects/mulan/files/datasets/enron.rar}}:
	      Es una colección de correos electrónicos seleccionados de entre los 500 mil
	      generados por empleados de la compañía eléctrica \textit{Enron} y filtrados
	      durante una investigación por corrupción \cite{hutchison_enron_2004}. Su
	      tamaño, que no supera los 2000 elementos, no es lo suficientemente grande
	      para ser considerado un flujo continuo voluminoso, pero sí cuenta con otras
	      propiedades como la inclusión de fechas y una evolución de los datos en el
	      tiempo \cite{read_scalable_2012}. Las etiquetas se dividen en cuatro
	      grupos, según su género (acuerdos laborales, correos meramente personales,
	      etc); según la información que incluyen, esto es, si el correo contiene
	      enlaces externos, adjuntos, reenvíos, etc; según el tono emocional que
	      reflejan y según el tópico principal que abordan.

	\item{Mediamill}
	      \footnote{\url{https://sourceforge.net/projects/mulan/files/datasets/mediamill.rar}}:
	      Es una colección generada a partir de 80 horas de video provenientes de
	      transmisiones de noticias durante noviembre de 2004
	      \cite{snoek_challenge_2006}. Se seleccionaron más de 43 mil ejemplos y fue
	      manualmente etiquetada con 101 conceptos, que pueden visualizarse en la
	      figura \ref{fig:mediamill}.

\end{description}

\begin{table}[htbp]
	\centering
	\input{tables/datasets.tex}
	\caption{Colecciones multi-etiquetas y sus características. N: número de
		instancias; A: número de atributos; L: número de etiquetas; LC: cardinalidad
		de etiquetas; LD: densidad de etiquetas.}
	\label{tab:datasets}
\end{table}

\begin{figure}
	\includegraphics[width=.9\linewidth]{figures/mediamill.jpg}
	\centering
	\caption{Los 101 conceptos semánticos asociados a la colección
		Mediamill.}
	\label{fig:mediamill}
\end{figure}

Estas son solo tres de las colecciones usualmente abordadas en la literatura y
se han seleccionado con el objetivo de diversificar el análisis. Enron es una
colección de pocas instancias pero muchas etiquetas, 20ng a la inversa, cuenta
con pocas etiquetas pero muchas instancias; y Mediamill, finalmente, es la
colección con más instancias que hay disponible y cuenta también con un número
relativamente alto de etiquetas.

Durante la ejecución de experimentos, cada colección será convertida a un flujo
sintético. Además, se generará una versión sintética de cada una, siguiendo la
técnica descripta en la sección \ref{generacion_flujos_sinteticos}.

\section{Software}

A continuación se describen las herramientas de software que fueron utilizadas
para la implementación y ejecución de los experimentos.

\begin{description}

	\item[scikit-multiflow]\footnote{\url{https://scikit-multiflow.github.io/}} Es
	      una librería disponible para el lenguaje de programación Python que provee
	      un \textit{framework} para implementar y comparar algoritmos de aprendizaje
	      automático en ambientes de flujos continuos de datos. Incluye pero no se
	      limita a problemas de clasificación multi-etiquetas
	      \cite{montiel_scikit-multiflow_2018}.

	\item[\acrshort{moa}]\footnote{\url{https://moa.cms.waikato.ac.nz/}}
	      \acrfull{moa} es un \textit{framework} para realizar minería de datos sobre
	      flujos continuos de datos, implementada en Java y de código libre.  Incluye
	      algoritmos de evaluación y de aprendizaje automático como clasificadores,
	      regresores, o de \textit{clustering}, pudiendo ser aplicados a problemas de
	      clasificación de etiqueta única o multi-etiquetas.  También incluye
	      herramientas para generar datos sintéticos. Tanto \acrshort{moa} como
	      scikit-multiflow facilitan la reiteración de experimentos con distintas
	      configuraciones, así como la comparación de resultados y la extensión de
	      funcionalidad \cite{bifet_moa_2010}.

	\item[scikit-learn]\footnote{\url{http://scikit-learn.org/stable/index.html}}
	      Es una librería del lenguaje de programación Python que brinda
	      herramientas para realizar evaluación, visualización y análisis de
	      resultados \cite{pedregosa_scikit-learn_2018}.

	\item[Mulan]\footnote{\url{http://mulan.sourceforge.net/index.html}} Es una
	      librería del lenguaje Java especializada en aprendizaje por
	      multi-etiquetas. Mulan incluye una variedad de colecciones de datos
	      multi-etiquetas que han sido la fuente de otros trabajos de la literatura
	      \cite{tsoumakas_mulan_2011}.

\end{description} \todo{nombres de herramientas van en cursiva?}

La herramienta \acrshort{moa} es usada para generar los flujos sintéticos y
provee del marco de trabajo en el cual se implementó el algoritmo de generación
descripto en \ref{generacion_flujos_sinteticos}. Los algoritmos de clasificación
fueron implementados en Python y están disponibles bajo la librería
\textit{scikit-multiflow}. La solución de ensamble \acrshort{efmp} también fue
implementada en esta librería. \textit{Scikit-learn}, por su parte, provee la
implementación de las métricas basadas en etiquetas, y las colecciones de datos
fueron extraídas de Mulan.

\section{Hardware}

Se ha recibido apoyo del \acrfull{cidetic}, el cual ha proveído de equipos de
altas prestaciones que han proporcionado la capacidad de cómputo necesaria para
llevar a cabo este proyecto. El equipamiento facilitado cuenta con dos nodos de
12 núcleos cada uno, el CPU es un Intel Xeon X5675 de 3.07 GHz de velocidad de
procesamiento, 12 Mb de memoria caché y 6 núcleos. El espacio de almacenamiento
disponible es de 1 Tb y la memoria RAM es de 142 Gb. \todo{Chequear estos datos}

El Sistema Operativo instalado es Ubuntu 18.04 LTS y cuenta con la versión 3.6.9
de Python, el instalador de paquetes Pip en su versión 20.3.3 y Java 1.8.

\section{Algoritmos}
\label{experimentos_algoritmos}

Se realizan los experimentos usando algoritmos multi-etiquetas disponibles en la
librería scikit-multiflow junto con las implementaciones de ensambles
presentadas en este trabajo: \acrfull{efmp} y su variación \acrshort{efmp2}.
Entre los algoritmos del tipo de transformación del problema se seleccionan los
de \acrfull{br}, \acrfull{cc} y \acrfull{mlht}. Tanto \acrshort{br} como
\acrshort{cc} usan \textit{naive} bayes como modelo de clasificación base y
\acrshort{mlht} es ejecutado en su versión basada en \acrfull{lp}, siguiendo los
procedimientos de \citeauthor{read_scalable_2012} \cite{read_scalable_2012}.

En lo que respecta a soluciones de ensamble, los modelos de \acrshort{efmp}
contarán ambos con tres clasificadores base, siendo estos los mencionados en el
párrafo anterior, es decir, \acrshort{cc}, \acrshort{br} y \acrshort{mlht}. La
comparación se hará contra el algoritmo \acrfull{dwm}, tal como ha sido definido
por sus autores \cite{kolter_dynamic_2007} pero adaptado a ambientes de
multi-etiquetas (ver sección \ref{tecnica_algoritmo_ensamble}), y se suman al
análisis los algoritmos de \acrfull{ebr} y \acrfull{ecc}, tal como fueron
definidos por \citeauthor{oza_online_2005} \cite{oza_online_2005} y también han
sido extendidos para soportar problemas de \acrshort{mll}
\cite{read_classifier_2011}. Los tres algoritmos de ensamble extraídos de la
literatura son configurados con diez clasificadores base de \textit{naive}
bayes, para imitar los experimentos conducidos por otros autores de la
literatura \cite{osojnik_multi-label_2017, read_scalable_2012,
	buyukcakir_novel_2018}.

La tabla \ref{tab:algoritmos} es un resumen de los algoritmos seleccionados
junto con los clasificadores base configurados, la referencia bibliográfica y la
clave que será usada en las tablas de resultados.

\begin{table}[htbp]
	\centering
	\begin{adjustbox}{max width=\textwidth}
		\input{tables/algorithms.tex}
	\end{adjustbox}
	\caption{Métodos de clasificación multi-etiquetas seleccionados para ambientes
		de flujos continuos de datos.}
	\label{tab:algoritmos}
\end{table}

\section{Métricas de Evaluación}

En la evaluación de algoritmos de clasificación se usan el conjunto de métricas
que han sido utilizadas en otros trabajos de la literatura, tanto en escenarios
de flujos \cite{sousa_multi-label_2018, zheng_survey_2020,
	osojnik_multi-label_2017} como en \textit{batch} \cite{madjarov_extensive_2012,
	zhang_multi-label_2010, gibaja_tutorial_2015} y fueron descriptas en la
sección \ref{mll_evaluacion}. Estas son:

\begin{description}

	\item[Métricas Basadas en Ejemplos]: \textit{Hamming score}, \textit{hamming
		      loss}, \textit{exact-match} (exactitud del subconjunto),
	      \textit{accuracy} (o exactitud, o \textit{jaccard index}), precisión,
	      \textit{recall} (o exhaustividad) y \textit{f1}.

	\item[Métricas Basadas en Etiquetas]: \textit{Accuracy} (micro), precisión
	      (micro), \textit{recall} (micro), \textit{f1} (micro),
	      \textit{accuracy} (macro), precisión (macro), \textit{recall} (macro)
	      y \textit{f1} (macro).

	\item[Métricas de Eficiencia]: Velocidad y tamaño del modelo.

\end{description}

La medición de velocidad comienza en el momento que inicia la predicción y
entrenamiento del modelo por primera vez y finaliza cuando el clasificador
termina de procesar la última instancia de la colección. Por lo tanto, quedan
afuera las etapas de evaluación, carga de la colección en memoria, generación
del flujo y configuración del entrenamiento. El consumo de memoria también es
monitoreado durante la ejecución del entrenamiento y predicción y toma en cuenta
la estructura completa del modelo y todos sus componentes, incluyendo pesos e
hiper-parámetros propios y de sus clasificadores base.

Los flujos sintéticos son analizados teniendo en cuenta los fenómenos propios de
colecciones del mundo real. A ese fin se estudia el sesgo de etiquetas, la
relación entre etiquetas, la distribución de etiquetas y el espacio de atributos
(ver sección \ref{mll_fenomenos}). \todo{es probable que este análisis se separe
	en una sección aparte y se aborde con mayor profundidad}

\section{Configuración Experimental}

En lo que respecta a modelos de aprendizaje automático, los experimentos fueron
desarrollados en el lenguaje Python usando la librería
\textit{scikit-multiflow}. Los algoritmos de transformación del problema se
aplican tal como han sido implementados en la librería con la salvedad del
\acrshort{mlht}, al que debió introducirle una modificación para manipular la
predicción, se usaba un arreglo disperso para representar las etiquetas
activadas, lo cual producía un desbordamiento de memoria en el entrenamiento de
colecciones grandes como la de Mediamill. Se lo suplantó por una estructura de
representación densa. En cuanto a los modelos de ensambles, se adaptaron las
implementaciones existentes de \acrshort{ebr}, \acrshort{ecc} y \acrshort{dwm}
para soportar múltiples etiquetas y para ello se debió modificar la etapa de
combinación de votos para hacer frente a la nueva dimensionalidad de los datos.
Por lo demás, la configuración de los algoritmos es la definida en la sección
\ref{experimentos_algoritmos}.

Para la etapa de evaluación se aplica la técnica de evaluación secuencial
predictiva (\textit{prequential}) con ventanas deslizantes, tal como se
recomienda para ambientes de flujos continuos \cite{gama_evaluating_2013}. Ante
cada ejemplo o ventana de ejemplos arribada el modelo primero realiza la
predicción y luego el entrenamiento. Finalmente las métricas de evaluación son
calculadas una vez procesados todos los ejemplos de la colección y a partir de
todas las predicciones producidas.  Notar que a partir de esta técnica el modelo
predice y entrena todas las instancias, y no solo un subconjunto de ellas como
sucede con la estrategia de \textit{holdout}. La ventana deslizante se configura
en $w = \frac{N}{20}$, es decir, se divide el número total de instancias del
flujo en 20 ventanas, siguiendo las directivas de \textcite{read_scalable_2012}.
Los resultados de la evaluación son agrupados según los tipos de métrica usados,
para facilitar el análisis.

Por otro lado, los flujo de datos sintéticos fueron generados a partir de las
colecciones 20ng, Enron y Mediamill. Por cada uno de ellos se generan tres
\textit{streams} sintéticos:

\begin{description}

	\item[MOA]: Es un stream generado usando el método de los autores de
	      referencia \cite{read_generating_2009}. El número de instancias es el
	      mismo de la colección original y el generador de atributos es
	      \acrfull{rbf} (ver sección~\ref{stream_syn}).

	\item[JC]: Es un stream generado usando el método presentado en la sección
	      ~\ref{generacion_flujos_sinteticos}. El número de instancias es el
	      mismo de la colección original y el generador de atributos es
	      \acrfull{rbf}.

	\item[JC\_BIG]: Es un stream similar a JC pero cuenta con un mayor número de
	      instancias. La idea es poder determinar si a mayor el tamaño del
	      \textit{stream} mayor es la similitud con la colección original.

\end{description}

Una vez generados estos flujos sintéticos se realizó un análisis para determinar
en qué grado se observan los fenómenos de la colección original en las
colecciones sintéticas. Estos fenómenos son el sesgo de etiquetas, la
distribución de etiquetas y la relación entre etiquetas. \todo{agregar espacio
	de atributos?} y se capturaron de la siguiente manera:

\todo{a completar}
\begin{description}

	\item[Sesgo de etiquetas]: Para observar el sesgo de etiquetas se toma la frecuencia de
	      cada etiqueta y se traza un gráfico de lineas para cada \textit{stream}, de esta
	      manera es posible visualizar cuánto se asemeja el sesgo de los datos sintéticos
	      al de los datos reales.

	\item[Distribución de etiquetas]: a completar.

	\item[Relación entre Etiquetas]: a completar.

\end{description}


\section{Resultados}

\subsection{Flujos Continuos Sintéticos}

\subsubsection{20ng}

\begin{table}[htbp]
	\centering
	\begin{adjustbox}{max width=\textwidth}
		\input{tables/syn/20ng_stats.tex}
	\end{adjustbox}
	\caption{Características de los \textit{streams} sintéticos generados sobre
		la colección 20ng.  N: número de instancias; L: número de etiquetas; LC:
		cardinalidad de etiquetas; LD: densidad de etiquetas.}
	\label{tab:syn_20ng_stats}
\end{table}

La tabla~\ref{tab:syn_20ng_stats} muestra las características de la colección
original y de los \textit{streams}. Allí se observa que la cardinalidad de la
colección apenas sobrepasa la unidad, lo que significa que la mayoría de sus
instancias tienen una única etiqueta. Esta característica logra ser capturada de
manera aproximada por los \textit{streams} JC y JC\_BIG pero no así por MOA que
asocia más de tres etiquetas por instancia. La
figura~\ref{fig:syn_20ng_label_skew} es una representación gráfica del sesgo de
etiquetas, y muestra que la colección original tiene alrededor de veinte
combinaciones con una frecuencia escalada cercana a la máxima y luego un
descenso brusco que culmina en la combinación 25, desde la cual se mantiene
cercana a la frecuencia escalada mínima. Esta tendencia es bien replicada en los
\textit{streams} JC pero no en MOA, donde el descenso es más escalonado y no
alcanza la zona baja del eje y. La
tabla~\ref{tab:syn_20ng_top_labels_combinations} muestra las principales 5
combinaciones de etiquetas para cada \textit{stream}. Cabe destacar que todas
las combinaciones en la tabla para los \textit{streams} JC y JC\_BIG son de una
etiqueta cada una, tal como el original, pero además JC captura 3 de las 5
combinaciones principales del original: $\{religion.cristian\}$,
$\{rec.sport.hockey\}$ y $\{sci.crypt\}$.

\begin{figure}[htbp]
	\includegraphics[width=\linewidth]{figures/experiments/syn/20ng/label_skew.png}
	\caption{Sesgo de etiquetas de los \textit{streams} generados sobre la colección
		20ng.}
	\label{fig:syn_20ng_label_skew}
\end{figure}

\begin{table}[htbp]
	\centering
	\begin{adjustbox}{max width=\textwidth}
		\input{tables/syn/20ng_top_labels_combinations.tex}
	\end{adjustbox}
	\caption{Sesgo de etiquetas - Principales combinaciones de los
		\textit{streams} generados sobre la colección 20ng.}
	\label{tab:syn_20ng_top_labels_combinations}
\end{table}

La figura~\ref{fig:syn_20ng_label_distribution} representa de manera gráfica la
distribución de las etiquetas. Allí se observa cómo los \textit{streams} aquí
presentados reproducen con eficacia la composición de la cardinalidad a lo largo
de los distintos tamaños de conjuntos de etiquetas. El gráfico de \textit{mean
	absolute error} ayuda a reforzar esta idea. En cuanto al tipo de distribución,
del cual se hace mención en el trabajo de referencia, los \textit{streams} JC y
JC\_BIG, tanto como el original, obedecen al tipo A, esto es, la mayoría de los
ejemplos tienen un conjunto de etiquetas de cardinalidad uno.


\begin{figure}[htbp]
	\includegraphics[width=\linewidth]{figures/experiments/syn/20ng/label_distribution.png}
	\includegraphics[width=\linewidth]{figures/experiments/syn/20ng/ld_mae.png}
	\caption{Distribución de etiquetas de los \textit{streams} generados sobre la colección
		20ng. Arriba se encuentra el gráfico con las frecuencias escaladas y
		abajo el \textit{mean absolute error} entre cada \textit{stream} y la
		colección original.}
	\label{fig:syn_20ng_label_distribution}
\end{figure}

Finalmente, la figura~\ref{fig:syn_20ng_label_relationship} es una
representación visual de la dependencia entre etiquetas. Ambos ejes del gráfico
constan de las etiquetas de la colección y cuánto mayor es la tonalidad de
blanco en la celda, mayor es la dependencia entre las dos etiquetas. Para 20ng
los gráficos de la colección original, JC y JC\_BIG, son casi idénticos entre sí
por lo que es posible aseverar que el uso de la matriz de correlaciones en la
generación de \textit{streams} sintéticos ha contribuido a reproducir el
fenómeno de la dependencia entre etiquetas para esta colección.

\begin{figure}[htbp]
	\includegraphics[width=\linewidth / 2]{figures/experiments/syn/20ng/20ng_relationship_graph.png}
	\includegraphics[width=\linewidth / 2]{figures/experiments/syn/20ng/JC_relationship_graph.png}
	\includegraphics[width=\linewidth / 2]{figures/experiments/syn/20ng/JC_BIG_relationship_graph.png}
	\includegraphics[width=\linewidth / 2]{figures/experiments/syn/20ng/MOA_relationship_graph.png}
	\caption{Relación entre etiquetas para cada \textit{stream} generado sobre
		la colección 20ng. Arriba a la izquierda: \textit{Stream} original. Arriba a la
		derecha: \textit{Stream} JC. Abajo a la izquierda: \textit{Stream}
		JC\_BIG. Abajo a la derecha: \textit{Stream} MOA.}
	\label{fig:syn_20ng_label_relationship}
\end{figure}

\subsubsection{Enron}

\begin{table}[htbp]
	\centering
	\begin{adjustbox}{max width=\textwidth}
		\input{tables/syn/enron_stats.tex}
	\end{adjustbox}
	\caption{Características de los \textit{streams} sintéticos generados sobre
		la colección Enron.  N: número de instancias; L: número de etiquetas; LC:
		cardinalidad de etiquetas; LD: densidad de etiquetas.}
	\label{tab:syn_enron_stats}
\end{table}

Partiendo de la tabla~\ref{tab:syn_enron_stats} se observa que el
\textit{stream} MOA se aproxima más al valor de cardinalidad de la colección
original que nuestra propuesta. Sin embargo, JC Y JC\_BIG, describen una curva
en el gráfico de la figura~\ref{fig:syn_enron_label_skew} que, en comparación
con MOA, tiene una mayor similitud con la curva de la colección original.  Se
adjunta la tabla~\ref{tab:syn_enron_top_labels_combinations} como complemento al
estudio del sesgo.

\begin{figure}[htbp]
	\includegraphics[width=\linewidth]{figures/experiments/syn/enron/label_skew.png}
	\caption{Sesgo de etiquetas de los \textit{streams} generados sobre la colección
		Enron.}
	\label{fig:syn_enron_label_skew}
\end{figure}

\begin{table}[htbp]
	\centering
	\begin{adjustbox}{max width=\textwidth}
		\input{tables/syn/enron_top_labels_combinations.tex}
	\end{adjustbox}
	\caption{Sesgo de etiquetas - Principales combinaciones de los
		\textit{streams} generados sobre la colección Enron.}
	\label{tab:syn_enron_top_labels_combinations}
\end{table}

Con respecto a la distribución de etiquetas
(figura~\ref{fig:syn_enron_label_distribution}) no es posible determinar si
alguno de los \textit{streams} refleja el fenómeno en mayor grado que otro. Al
mismo tiempo, si bien ninguno de ellos logra reproducir con exactitud la
composición de la cardinalidad entre conjuntos de etiquetas, hay un grado de
similitud entre curvas (ver gráfico de \textit{mean absolute error}) que podría
ser aceptable, dependiendo de la tarea a resolver. En cuanto al tipo de
distribución, del cual se hace mención en el trabajo de referencia, todos los
\textit{streams} sintéticos obedecen al tipo B, es decir, la mayoría de los
ejemplos tienen una cardinalidad de etiquetas mayor que uno.

\begin{figure}[htbp]
	\includegraphics[width=\linewidth]{figures/experiments/syn/enron/label_distribution.png}
	\includegraphics[width=\linewidth]{figures/experiments/syn/enron/ld_mae.png}
	\caption{Distribución de etiquetas de los \textit{streams} generados sobre la colección
		Enron. Arriba se encuentra el gráfico con las frecuencias escaladas y
		abajo el \textit{mean absolute error} entre cada \textit{stream} y la
		colección original.}
	\label{fig:syn_enron_label_distribution}
\end{figure}

Por último, el fenómeno de la dependencia entre etiquetas es representado
visualmente por la figura~\ref{fig:syn_enron_label_relationship}. Tal como
sucedió con la colección 20ng, los gráficos de JC y JC\_BIG para Enron reflejan
una coloración muy similar al del original, aunque con una tonalidad de blanco
menos intensa. Este comportamiento podría estar emparentado con la cardinalidad
de etiquetas, que en estos \textit{streams} sintéticos es menor. No obstante, se
requieren más estudios para arribar a una conclusión al respecto.

\begin{figure}[htbp]
	\includegraphics[width=\linewidth / 2]{figures/experiments/syn/enron/enron_relationship_graph.png}
	\includegraphics[width=\linewidth /
		2]{figures/experiments/syn/enron/JC_relationship_graph.png}
	\includegraphics[width=\linewidth /
		2]{figures/experiments/syn/enron/JC_BIG_relationship_graph.png}
	\includegraphics[width=\linewidth /
		2]{figures/experiments/syn/enron/MOA_relationship_graph.png}
	\caption{Relación entre etiquetas para cada \textit{stream} generado sobre
		la colección Enron. Arriba a la izquierda: \textit{Stream} original. Arriba a la
		derecha: \textit{Stream} JC. Abajo a la izquierda: \textit{Stream}
		JC\_BIG. Abajo a la derecha: \textit{Stream} MOA.}
	\label{fig:syn_enron_label_relationship}
\end{figure}

\subsubsection{Mediamill}

\begin{table}[htbp]
	\centering
	\begin{adjustbox}{max width=\textwidth}
		\input{tables/syn/mediamill_stats.tex}
	\end{adjustbox}
	\caption{Características de los \textit{streams} sintéticos generados sobre
		la colección Mediamill.  N: número de instancias; L: número de etiquetas; LC:
		cardinalidad de etiquetas; LD: densidad de etiquetas.}
	\label{tab:syn_mediamill_stats}
\end{table}

La tabla~\ref{tab:syn_mediamill_stats} muestra que el \textit{stream} MOA hace
un buen trabajo en aproximar la cardinalidad de la colección original y presenta
la curva de sesgo más cercana a ella (ver
figura~\ref{fig:syn_mediamill_label_skew}). Se adjunta la
tabla~\ref{tab:syn_20ng_top_labels_combinations} como complemento al estudio del
sesgo.

\begin{figure}[htbp]
	\includegraphics[width=\linewidth]{figures/experiments/syn/mediamill/label_skew.png}
	\caption{Sesgo de etiquetas de los \textit{streams} generados sobre la
		colección Mediamill.}
	\label{fig:syn_mediamill_label_skew}
\end{figure}

\begin{table}[htbp]
	\centering
	\begin{adjustbox}{max width=\textwidth}
		\input{tables/syn/mediamill_top_labels_combinations.tex}
	\end{adjustbox}
	\caption{Sesgo de etiquetas - Principales combinaciones de los
		\textit{streams} generados sobre la colección Mediamill.}
	\label{tab:syn_mediamill_top_labels_combinations}
\end{table}

Con respecto a la distribución de etiquetas
(figura~\ref{fig:syn_mediamill_label_distribution}) las conclusiones son
similares a las realizadas a este efecto para Enron. No es posible determinar
con certeza que alguno de los \textit{streams} refleja el fenómeno en mayor
grado que otro, e incluso, si se analiza el gráfico de \textit{mean absolute
	error}, se puede observar que hay 3 puntos donde la curva de JC se aproxima más
al del original y 3 donde el más próximo es MOA. En cuanto al tipo de
distribución, del cual se hace mención en el trabajo de referencia, todos los
\textit{streams} sintéticos obedecen al tipo B, es decir, la mayoría de los
ejemplos tienen una cardinalidad de etiquetas mayor que uno.

\begin{figure}[htbp]
	\includegraphics[width=\linewidth]{figures/experiments/syn/mediamill/label_distribution.png}
	\includegraphics[width=\linewidth]{figures/experiments/syn/mediamill/ld_mae.png}
	\caption{Distribución de etiquetas de los \textit{streams} generados sobre la colección
		Mediamill. Arriba se encuentra el gráfico con las frecuencias escaladas y
		abajo el \textit{mean absolute error} entre cada \textit{stream} y la
		colección original.}
	\label{fig:syn_mediamill_label_distribution}
\end{figure}

También sobre el fenómeno de la dependencia entre etiquetas se pueden hacer
conclusiones similares a las de Enron (ver
figura~\ref{fig:syn_mediamill_label_relationship}). Los gráficos de JC y JC\_BIG
nuevamente reflejan una coloración muy similar al del original, y con una
tonalidad de blanco menos intensa que podría ser producto de un menor valor de
cardinalidad existente en estos \textit{streams} y con respecto al original.

\begin{figure}[htbp]
	\includegraphics[width=\linewidth /
		2]{figures/experiments/syn/mediamill/mediamill_relationship_graph.png}
	\includegraphics[width=\linewidth /
		2]{figures/experiments/syn/mediamill/JC_relationship_graph.png}
	\includegraphics[width=\linewidth /
		2]{figures/experiments/syn/mediamill/JC_BIG_relationship_graph.png}
	\includegraphics[width=\linewidth /
		2]{figures/experiments/syn/mediamill/MOA_relationship_graph.png}
	\caption{Relación entre etiquetas para cada \textit{stream} generado sobre
		la colección Mediamill. Arriba a la izquierda: \textit{Stream} original.
		Arriba a la derecha: \textit{Stream} JC. Abajo a la izquierda:
		\textit{Stream} JC\_BIG. Abajo a la derecha: \textit{Stream} MOA.}
	\label{fig:syn_mediamill_label_relationship} \end{figure}

\subsection{Clasificaciones}

La metodología propuesta permitió evaluar los diferentes algoritmos de
clasificación multi-etiqueta para los diferentes \textit{streams} utilizando las
configuraciones sin ensambles, los ensambles de referencias y los métodos de
ensamble propuestos. Los resultados se dividen en métricas de ajustes del modelo
basadas en ejemplos (tabla~\ref{tab:example_based}), métricas basadas en
etiquetas (tabla \ref{tab:label_based}), y por último las métricas de eficiencia
(tabla \ref{tab:efficiency}) que cuantifican el tiempo de procesamiento y
espacio de almacenamiento de los modelos. Se marca en negrita la celda
correspondiente al modelo que obtuvo el mejor valor de métrica para la
correspondiente colección de datos. Para cerrar la sección se hace una
comparativa contra experimentos de la literatura de referencia.

\subsubsection{Resultados para Métricas Basadas en Ejemplos}

\begin{table}[htbp]
	\centering
	\begin{adjustbox}{max width=\textwidth}
		\input{tables/evaluations/example_based_1.tex}
	\end{adjustbox}
	\begin{adjustbox}{max width=\textwidth}
		\input{tables/evaluations/example_based_2.tex}
	\end{adjustbox}
	\caption{Resultados de métricas basadas en ejemplos sobre los
		\textit{streams} seleccionados para cada algoritmo evaluado.}
	\label{tab:example_based}
\end{table}

\begin{figure}
	\includegraphics[width=\linewidth,height=10cm]{figures/experiments/classification/f1_ex.png}
	\caption{Comparativa de modelos bajo la métrica \textit{f1} basada en
		ejemplos.}
	\label{fig:comparativa_f1_ex}
\end{figure}

Los valores de F1 obtenidos para la evaluación basada en ejemplos (Tabla
\ref{tab:example_based}) muestra que \acrshort{efmp} y \acrshort{efmp2} fueron
mejores que los \textit{baselines} de ensambles en todos los casos.  Además,
superó a los que no utilizan ensambles en el \textit{stream} de Enron.  En los
casos de 20ng, \acrshort{efmp} fue superado en un 0.001\% por \acrshort{br} y en
Mediamill \acrshort{mlht} superó a \acrshort{efmp} en un 0.015\%. Para el caso
de \textit{exact-match} el modelo dominante es \acrshort{mlht}, lo cual es un
resultado en consonancia con otros estudios de la
literatura~\cite{read_scalable_2012,osojnik_multi-label_2017,zheng_survey_2020},
y los modelos propuestos se ubican en segundo lugar para dos de las tres
colecciones. En cuanto al \textit{hamming score} los resultados son muy
similares entre colecciones de datos, con los modelos de \acrshort{dwm} sacando
una leve ventaja para 20ng y Enron pero siendo superado por \acrshort{efmp} y
\acrshort{mlht} para Mediamill. También se observan resultados competitivos en
la métrica de \textit{accuracy} donde \acrshort{efmp} supera a todos los modelos
para Enron, incluyendo al de \acrshort{mlht} que es el dominante para Mediamill
y 20ng.

La figura~\ref{fig:comparativa_f1_ex} muestra la comparativa de rendimientos
entre modelos bajo la métrica de \textit{f1}, ordenados desde el menos
performante al más performante y con los modelos aquí presentados en color
negro. Se puede observar cómo en cada \textit{stream} el modelo \acrshort{efmp}
se sitúa entre los dos mejores, siendo el de mejor rendimiento para Enron. De
manera similar, \acrshort{efmp2} se sitúa en cuarto puesto para Enron y quinto
para los demás. Es de notar que otros modelos no logran emparejar rendimientos
entre \textit{streams}, véase el caso de \acrshort{mlht} por ejemplo, que es el
mejor para Mediamill pero cae en el último puesto para Enron. Este resultado es
coherente con la idea de que los modelos derivados de \acrlong{ht} requieren de
un mayor número de instancias para identificar el mejor punto de corte de un
nodo y lograr mejores evaluaciones~\cite{read_scalable_2012}. Algo similar
sucede con los dos modelos de \acrshort{dwm} que logran valores altos para
Mediamill pero se ubican entre los tres menos performantes para Enron y 20ng.

\subsubsection{Resultados para Métricas Basadas en Etiquetas}

\begin{table}[htbp]
	\centering
	\begin{adjustbox}{max width=\textwidth}
		\input{tables/evaluations/label_based_macro.tex}
	\end{adjustbox}
	\begin{adjustbox}{max width=\textwidth}
		\input{tables/evaluations/label_based_micro.tex}
	\end{adjustbox}
	\caption{Resultados de métricas basadas en etiquetas sobre los
		\textit{streams} seleccionados para cada algoritmo evaluado.}
	\label{tab:label_based}
\end{table}

\begin{figure}
	\includegraphics[width=\linewidth,height=10cm]{figures/experiments/classification/f1_macro.png}
	\caption{Comparativa de modelos bajo la métrica \textit{f1} con promedio
		macro, basada en etiquetas.}
	\label{fig:comparativa_f1_macro}
\end{figure}

\begin{figure}
	\includegraphics[width=\linewidth,height=10cm]{figures/experiments/classification/f1_micro.png}
	\caption{Comparativa de modelos bajo la métrica \textit{f1} con promedio
		micro, basada en etiquetas.}
	\label{fig:comparativa_f1_micro}
\end{figure}

La métrica de \textit{f1} macro muestra resultados favorecedores para los
modelos presentados. \acrshort{efmp2} obtuvo un valor superior para Mediamill y
\acrshort{efmp} fue el mejor para 20ng y el segundo mejor para Enron, por
centésimas de diferencia con respecto al modelo \acrshort{br}. En lo que
respecta a la comparativa entre soluciones de ensambles, \acrshort{efmp} y
\acrshort{efmp2} superan a las demás para todas las colecciones evaluadas.  Con
relación a los modelos de \acrshort{dwm}, estos muestran una disparidad entre
los valores de precisión y \textit{recall}. Véase por ejemplo el caso de
\acrshort{dwm} (\acrshort{cc}) para 20ng, donde logra más de un 0.8 de precisión
(mejor clasificador) pero un \textit{recall} por debajo de 0.2 (segundo peor
clasificador). Mismo caso pero a la inversa con \acrshort{dwm} (\acrshort{br})
para Mediamill, el cual consigue alrededor de 0.4 de \textit{recall} (tercer
mejor clasificador) pero apenas un 0.06 de precisión (tercer peor
clasificador).  Esta disparidad logra suavizarse en los modelos de
\acrshort{efmp} presentados y se ve reflejado en valores más altos de
\textit{f1}.

También son favorecedores los valores de las métricas de \textit{f1} micro para
los modelos presentados. \acrshort{efmp} es el mejor para las colecciones 20ng y
Enron y es apenas superado por \acrshort{mlht} para el \textit{stream} de
Mediamill. En la comparativa de métodos de ensambles, \acrshort{efmp} es el
mejor modelo para todos las métricas a excepción del caso de \textit{recall}
para Mediamill (donde \acrshort{ebr} obtiene el mejor valor), y los casos de
precisión para Enron y 20ng, donde \acrshort{dwm} (\acrshort{cc}) logra una
clara diferencia. Al respecto de este último modelo se puede hacer las mismas
consideraciones en cuanto a la disparidad entre precisión y \textit{recall}.

Las figuras~\ref{fig:comparativa_f1_macro} y~\ref{fig:comparativa_f1_micro}
muestra la comparativa de rendimientos entre modelos bajo las métricas de
\textit{f1} macro y micro, respectivamente, y con los mejores modelos
posicionados más a la derecha. Para la métrica macro-promediada se puede
observar que al menos uno de los dos modelos de \acrshort{efmp} se posiciona
entre los mejores tres para cada colección y como el mejor método de ensambles.
Lo mismo sucede con la métrica micro-promediada, donde \acrshort{efmp} supera a
los métodos de \acrshort{br} y \acrshort{cc} para 20ng y Enron y queda por
debajo de \acrshort{mlht} y \acrshort{ecc} para Mediamill.

\subsubsection{Resultados para Métricas de Eficiencia}

\begin{table}[htbp]
	\centering
	\begin{adjustbox}{max width=\textwidth}
		\input{tables/evaluations/efficiency.tex}
	\end{adjustbox}
	\caption{Resultados de métricas de eficiencia sobre los
		\textit{streams} seleccionados para cada algoritmo evaluado.}
	\label{tab:efficiency}
\end{table}

Tal como es de esperar, la tabla~\ref{tab:efficiency} muestra que los modelos
\textit{baselines} que no son soluciones de ensambles hacen un uso de espacio
menor que los modelos de ensambles y logran tiempos de ejecución
significativamente menores. Sin embargo, en la comparativa entre ensambles, los
algoritmos propuestos (\acrshort{efmp} y \acrshort{efmp2}) reducen tanto el
espacio de almacenamiento como el tiempo de procesamiento de los
\textit{streams} de Enron y 20ng. Mientras que para Mediamill, \acrshort{ebr}
hace un uso significativamente menor de tiempo que los ensambles presentados.
Vale destacar que los modelos de \acrshort{efmp} logran mejorar los tiempos de
ejecución de sus predecesores, los ensambles \acrshort{dwm}.

\subsubsection{Comparativa contra Literatura de Referencia}

A partir de los resultados obtenidos se realiza una comparativa contra otros
estudios del campo. A este fin se seleccionaron los trabajos de
\citeauthor{osojnik_multi-label_2017}
(\citeyear{osojnik_multi-label_2017})~\cite{osojnik_multi-label_2017},
\citeauthor{roseberry_multi-label_2018}
(\citeyear{roseberry_multi-label_2018})~\cite{roseberry_multi-label_2018},
\citeauthor{buyukcakir_novel_2018}
(\citeyear{buyukcakir_novel_2018})~\cite{buyukcakir_novel_2018} y
\citeauthor{sousa_multi-label_2018}
(\citeyear{sousa_multi-label_2018})~\cite{sousa_multi-label_2018}. Si bien las
métricas y colecciones utilizadas varían según el estudio, todos los trabajos
parten de una configuración experimental similar a la de este trabajo y usan el
método \textit{prequential} para evaluar rendimientos.

\citeauthor{osojnik_multi-label_2017} presentaron experimentos sobre las
colecciones de 20ng y Enron bajo métricas basadas en ejemplos (\textit{hamming
	score}, \textit{f1} y \textit{exact-match}), métricas basadas en etiquetas
(precisión, \textit{recall} y \textit{f1}, todas ellas con promedio micro y
macro). Comenzando por las métricas basadas en ejemplos, el modelo
\textit{iSOUP-MT} es el que mejor \textit{hamming score} obtiene en sus
estudios, con un valor de 0.9523, y es levemente superado por \acrshort{efmp}
(0.954) y \acrshort{efmp2} (0.955). Para el caso de Enron el ganador es
\textit{iSOUP-MT} (en su versión de ensambles) con un valor de 0.942 y supera a
\acrshort{efmp2} (0.936). En cuanto al \textit{exact-match} nuestras soluciones
superan a la mejor solución de los autores, iSOUP-RT (0.117), en un 2.05\% para
20ng y son superadas en un 6.25\% por el modelo iSOUP-MT para Enron (0.244). En
lo que respecta al \textit{f1}, \acrshort{efmp} supera en un 2.8\% a iSOUP-RT
(0.118) para 20ng y en poco más de un 1\% a iSOUP-MT para Enron (0.329).

Con respecto a las métricas basadas en etiquetas los resultados también
favorecen a los métodos aquí presentados. Para el \textit{stream} 20ng
\acrshort{efmp2} supera en un 25.5\% a iSOUP-RT bajo la métrica de precisión
macro, en un 238\% en \textit{recall} macro a iSOUP-MT y en un 142\% en
\textit{f1} a ese mismo modelo. Para Enron nuestros modelos superan en un 111\%,
156\% y 164\% a iSOUP-RT para las mismas medidas mencionadas, respectivamente.
Las métricas de promedio micro también favorecen a nuestros modelos. Para 20ng
\acrshort{efmp} es superado en un 41.1\% por iSOUP-MT (en versión ensamble) en
precisión, supera en un 213.6\% a iSOUP-MT en \textit{recall} y en un 125\% en
\textit{f1}. Para Enron es superado en 33.3\% por iSOUP-MT (en versión ensamble)
en precisión pero consigue superar en un 45.5\% a iSOUP-RT en \textit{recall} y
en un 10.8\% en \textit{f1}.

\citeauthor{sousa_multi-label_2018} han presentado experimentos sobre los tres
\textit{streams} y bajo métricas basadas en ejemplos, en particular las de
\textit{accuracy}, \textit{exact-match}, precisión, \textit{recall} y
\textit{f1}. Para la comparativa se toma el mejor modelo de los autores para
cada métrica. Comenzando por la métrica de \textit{exact-match} los autores han
logrado mejores resultados. Nuestros modelos son superados en un 50.6\% para
20ng, en un 71.7\% para Enron y en un 75.5\% para Mediamill. También para la
precisión, recall y \textit{f1} \citeauthor{sousa_multi-label_2018} han logrado
mejores resultados en general.  En precisión logran superar en un 42.5\% a
\acrshort{efmp} para 20ng, en un 25.6\% a \acrshort{efmp2} para Enron y son
superados en un 0.5\% por \acrshort{efmp} para Mediamill. En \textit{recall}
superan en un 27.5\% a nuestros modelos para 20ng, en un 29\% para Enron y en un
7\% para Mediamill.  Finalmente, en \textit{f1} superan en un 37\% a nuestros
modelos para 20ng, en un 23\% para Enron y en un 15\% para Mediamill. No
obstante, los autores no presentan resultados bajo métricas basadas en
etiquetas.

\citeauthor{roseberry_multi-label_2018}, por su parte, diseñaron el modelo
ML-SAM-kNN y lo pusieron a prueba con las tres colecciones y las métricas de
\textit{exact-match} y \textit{f1} basado en ejemplos. En la comparativa
obtuvimos que \acrshort{efmp} es superado en un 26\% para 20ng, en un 86\% para
Enron y en un 92\% para Mediamill. No obstante, bajo la métrica de \textit{f1},
nuestros modelos superan en un 65\% y 229\% a sus modelos para 20ng y Enron
respectivamente y es superado en un 26\% para Mediamill. Los autores no
realizaron pruebas sobre métricas basadas en etiquetas.

Finalmente, \citeauthor{buyukcakir_novel_2018} presentaron el modelo de
ensambles \textit{GOOWE-ML} bajo las métricas de \textit{hamming score},
\textit{accuracy} basado en ejemplos, \textit{f1} basado en ejemplos y
\textit{f1} micro, basado en etiquetas. Si bien realizaron pruebas sobre varios
\textit{streams} el único en común con este trabajo es el de 20ng. Dicho esto,
su modelo consigue mejores valores para las métricas de \textit{f1} micro,
\textit{accuracy}, y \textit{f1} basado en ejemplos (13\%, 24\% y 26\% de
mejora, respectivamente) y peores valores para la métrica de \textit{hamming
	score} donde nuestros modelos lo superan en un 0.3\%.

En resumen, el resultado de los métodos propuestos muestra que son competitivos
respecto a la literatura de referencia. En particular, para las pruebas
realizadas con el conjunto de datos 20NG los valores de \textit{f1} basado en
ejemplos obtenidos superan a~\cite{osojnik_multi-label_2017} pero no son mejores
que otros como~\cite{sousa_multi-label_2018, buyukcakir_novel_2018,
	roseberry_multi-label_2018}.  En las pruebas realizadas con Enron, los métodos
propuestos superan a~\cite{osojnik_multi-label_2017}, duplican el rendimiento
de~\cite{roseberry_multi-label_2018} y son superados
por~\cite{sousa_multi-label_2018}. Finalmente, para el conjunto de datos
Mediamill tanto~\cite{sousa_multi-label_2018}
como~\cite{roseberry_multi-label_2018} superan nuestra propuesta.



\chapter{Metodología}

Conforme a los objetivos planteados en la sección~\ref{intro_objetivos} se
presentan las colecciones y algoritmos que serán evaluados junto con el
escenario de flujos continuos diseñado a este fin.

Se seleccionan tres colecciones de datos de multi-etiquetas que han sido puntos
de referencia en otros trabajos de investigación. Cada uno de ellos es
transformado en un flujo continuo de datos que cumple con las características
presentadas en la sección~\ref{stream_caracteristicas}. A su vez, se generan
instancias sintéticas que sean fieles a las cualidades subyacentes de los datos
originales.  Para ello, se ha diseñado un algoritmo basado en la implementación
de \citeauthor{read_multi-label_2008} \cite{read_multi-label_2008} pero que hace
uso de la matriz de probabilidades condicionales entre pares de etiqueta para
respetar sus interdependencias.

La etapa de entrenamiento se lleva a cabo con algoritmos de clasificación
multi-etiquetas que han sido adaptados a ambientes de flujos continuos para
hacer frente a las cualidades incrementales inherentes a este contexto. Se
seleccionan algoritmos de la familia de \comillas{Transformación del problema} y
\comillas{Adaptación del algoritmo} \todo{por el momento no se experimentó con
	algoritmos AA en Python}, junto con soluciones de ensamble, a fines explorativos
y para extender el conocimiento sobre sus fortalezas y debilidades. Los
experimentos se realizan con algoritmos implementados en el lenguaje de
programación Python.  Aquellos que no soportan datos de múltiples etiquetas han
sido acondicionados a ese fin de acuerdo al diseño especificado en la literatura
y consultando las respectivas implementaciones en otros lenguajes de
programación, de hallarse estas disponibles al público.

De manera complementaria, se diseña una solución de ensambles llamada
\acrfull{efmp} \todo{nombre tentativo}, basada en las implementaciones
existentes. La misma usa como clasificadores base tres algoritmos de
\acrshort{mll} diferentes, que se mantienen fijos durante todo el entrenamiento.
Además, el ensamble mantiene una ponderación de cada clasificador de acuerdo a
su rendimiento, penalizando por cada etiqueta mal clasificada, y la combinación
de los votos se lleva a cabo por mayoría de voto ponderada. La implementación se
basa en la presentada
por~\citeauthor{kolter_dynamic_2007}~\cite{kolter_dynamic_2007}, quienes también
ponderan los clasificadores pero usan un único tipo de clasificador base y no
contemplan problemas de múltiples etiquetas. Los experimentos se realizan con
dos versiones, una de ellas se entrena con todas las instancias del subconjunto
de entrenamientos y la otra tomando muestreos siguiendo la distribución de
\textit{poisson}, tal como se realiza para ensambles del tipo de \textit{Oza
	bagging} \cite{oza_online_2005}.

Para la etapa de evaluación se sigue la estrategia
\comillas{\textit{Prequential}}, descripta en la
sección~\ref{stream_evaluacion}, y se aplican métricas basadas en etiquetas y
ejemplos, se mide la eficiencia de los modelos en términos de velocidad y
espacio de almacenamiento y se analizan los resultados obtenidos.

El marco metodológico de este proyecto se ajusta a los procedimientos efectuados
previamente por otros investigadores de la literatura
\cite{osojnik_multi-label_2017, sousa_multi-label_2018, buyukcakir_novel_2018,
	zheng_survey_2020, read_scalable_2012}. Con ello se busca expandir el
conocimiento empírico de los algoritmos al mismo tiempo que proporcionar nuevos
estudios que sean contrastables con los ya existentes.  Se destaca el trabajo de
\citeauthor{read_scalable_2012} \cite{read_scalable_2012}, quienes analizan
algoritmos multi-etiquetas con flujos reales y sintéticos, pero a diferencia de
este trabajo, generan instancias sintéticas para colecciones nuevas y sin
basarse en colecciones reales específicas. La implementación del generador que
usaron en sus experimentos se encuentra disponible al público
\cite{read_moa_nodate} y ha sido el punto de partida para desarrollar la técnica
aquí propuesta.  \citeauthor{buyukcakir_novel_2018}, por su parte, no generan
flujos sintéticos pero conducen experimentos similares en lo que respecta al
análisis de algoritmos, poniendo el foco en modelos de ensambles.  La
implementación de sus experimentos también ha sido liberada al
público~\footnote{\url{https://github.com/abuyukcakir/gooweml}}.

\section{Técnicas Propuestas}

En esta sección se describen dos técnicas implementadas para este trabajo: un
generador de instancias sintéticas para flujos continuos de datos y el diseño de
una solución de ensambles para realizar clasificaciones.

\subsection{Generación de Flujos Sintéticos}
\label{generacion_flujos_sinteticos}

El generador presentado es un algoritmo que emplea técnicas probabilísticas para
hallar dependencias entre etiquetas y reproducirlas en las nuevas instancias. La
existencia de interdependencias entre etiquetas ha sido explorada reiteradas
veces en la literatura \cite{tsoumakas_multi-label_2007, read_multi-label_2008}
y se ha demostrado que existen dependencias condicionales e incondicionales,
esto es, etiquetas que dependen entre sí dado uno o más atributos de una
instancia (dependencia condicional), y etiquetas cuya dependencia existe para
todo el conjunto de instancias (dependencia incondicional). Estas dos cualidades
son directamente extraídas de las colecciones reales y a partir de ellas se
genera el espacio de atributos y etiquetas que, al fusionarse, constituyen la
instancia sintética.

La dependencia incondicional parte de la idea de que hay etiquetas que se
activan en conjunto con frecuencia y otras que son mutuamente excluyentes. Véase
el caso de las etiquetas \comillas{\texttt{Ficción}} y \comillas{\texttt{No
		Ficción}}, por ejemplo, que son excluyentes en el dominio de géneros literarios.
Para capturar esta relación se acude al concepto de probabilidad a priori y
probabilidad condicional de etiquetas. La probabilidad a priori de una etiqueta
es obtenida a partir de observar su frecuencia relativa en la colección
normalizada por la Cardinalidad de etiquetas. \todo{Chequear fórmula con
	director!} La frecuencia relativa se formula de la manera tradicional:

\begin{equation}
	FrecRelE_{j} = \frac{1}{m} \sum_{i=1}^{m} y_{i,j}
\end{equation}

La normalización toma en cuenta el valor de cardinalidad de etiquetas del
conjunto de datos, esto bajo la recomendación de los autores del trabajo de
referencia \cite{read_scalable_2012}.

\begin{equation}
	NormCardE = \frac{1}{CardE} \sum_{j=1}^{q} FrecRelE_{j}
\end{equation}

Donde $CardE$ se define tal como en \ref{eq:mll_card}, esto es:

\begin{equation}
	CardE(D) = \frac{1}{m} \sum_{i=1}^{m} \left\|Y_{i}\right\|
\end{equation}

Luego, la probabilidad a priori de la etiqueta $j$ se expresa de la forma:

\begin{equation}
	P(E_{j}) =\min{(1, \frac{FrecRelE_{j}}{NormCardE})}
\end{equation}

El resultado es un vector $[P(E_{1}), P(E_{2}),\dots, P(E_{q})]$.

A partir de $P(E_{j})$ se puede calcular la matriz condicional $\theta$ sobre
los pares de etiquetas, esto es, $\theta_{j,k} = P(Y_{j} = 1 \mid Y_{k} = 1)$,
donde  $1 \leq j \leq L$ y $1 \leq k \leq L$ con $j \neq k$. \todo{L es menor o igual a j en la bibliografía, es
	un error?} Con el vector de probabilidades a priori y extrayendo las
co-ocurrencias de cada par de etiquetas en toda la colección, es posible obtener
cada valor de la matriz $\theta$, aplicando la probabilidad condicional:

\begin{equation}
	P(Y_{j} = 1 \mid Y_{k} = 1) = \frac{P(Y_{k} = 1 \cap Y_{j} = 1)}{P(Y_{k})}
\end{equation}

Luego, la dependencia entre etiquetas es modelada como la distribución conjunta:

\begin{equation}
	\label{eq:syn_joint}
	p_{\theta}(y) = P(y_{1}) \prod_{j=2}^q P(y_{j} \mid y_{j-1})
\end{equation}

Posteriormente, se realiza la generación del conjunto de etiquetas para la
instancia sintética. El algoritmo~\ref{alg:generar_etiquetas} muestra las
instrucciones ejecutadas para concretar esta tarea. Cabe aclarar que $sample()$
retorna un índice de etiqueta de acuerdo a una función de masa de probabilidad
basada en las probabilidades a priori, y $random()$ produce un número aleatorio
de distribución uniforme.

% textidote: ignore begin
\begin{center}
	\begin{algorithm}[H]
		\label{alg:generar_etiquetas}
		\SetAlgoLined
		\DontPrintSemicolon
		\KwIn{
			$q$:  Número de etiquetas de la colección,
			$p$: vector de probabilidades a priori,
			$p_{\theta}(y)$: función definida en fórmula~\ref{eq:syn_joint}
		}
		\KwOut{$y$: las etiquetas generadas.}
		$y \gets \emptyset_{q}$\;
		$j \gets sample(p)$\;
		$y_{j} \gets 1$\;
		$i \gets 0$ \;
		\While{$i < q$}{
			\lIf{$i = j$}{$\Continue$}
			$y^{\prime} \gets y$\;
			$y^{\prime}_{i} \gets 1$\;
			\lIf{$p_{\theta}(y^{\prime}) > random()$}{$y \gets y^{\prime}$ }
			$i \gets i+1$\;
		}
		\caption{Algoritmo de generación del conjunto de etiquetas para una instancia
			sintética}
	\end{algorithm}
\end{center}
% textidote: ignore end

Una vez generado el conjunto de etiquetas resta generar los valores de atributos
para la instancia. Para ello se retoma el concepto ya mencionado de
\comillas{Dependencia Condicional}, para conocer en qué medida la presencia de
un atributo activa una o más etiquetas en la instancia, o expresado en términos
formales, hallar el término $P(y|x)$ tal que:

\begin{equation}
	P(y|x) = P(x|y)P(y)
\end{equation}

Como el cálculo de la probabilidad conjunta es altamente compleja se define una
función de mapeo $\zeta[a] \mapsto y_{a}$, donde $y_{a}$ es la combinación de
etiquetas más probable para el atributo $a$.  La función $\theta$ se obtiene a
través de muestreos sucesivos del generador de etiquetas, y guardando las $A$
combinaciones más frecuentes, siendo el número total de atributos. Al mismo
tiempo, el vector $x$ candidato es obtenido usando un generador binario tal como
los descriptos en la sección~\ref{stream_syn}. El
algoritmo~\ref{alg:generar_atributos} muestra un pseudocódigo de cómo se
completa el proceso. Notar que el generador binario $g$ produce dos vectores de
atributos candidatos, uno por cada clase, luego si la combinación de etiquetas
para el atributo $a$ es un subconjunto de las etiquetas generadas se toma el
valor del vector de atributos positivos. Caso contrario, se toma del vector de
negativos.

Finalmente, la instancia sintética se forma a partir de la salida de ambos
algoritmos, siendo de la forma $(x, y)$. Este proceso será repetido para cada
instancia que se solicite al generador a fin de generar el flujo sintético para
la colección dada. El objetivo es obtener colecciones sintéticas que se asemejen
a datos del mundo real, por lo tanto, la evaluación de los resultados se hará
mediante un análisis de sus cualidades en relación con fenómenos hallados en
datos reales (ver sección~\ref{mll_fenomenos}), y se contrastan los datos
generados en este marco contra los producidos en el trabajo de referencia.

% textidote: ignore begin
\begin{center}
	\begin{algorithm}[H]
		\label{alg:generar_atributos}
		\SetAlgoLined
		\DontPrintSemicolon
		\KwIn{
			$A$:  Número de atributos de la colección,
			$g$: Generador de atributos,
			$\zeta$: Función de mapeo.
		}
		\KwOut{$x$: El vector de atributos generado.}
		$x \gets \emptyset_{A}$\;
		$positivos \gets g(1)$ \;
		$negativos \gets g(0)$ \;
		$i \gets 0$ \;
		\While{$i < A$}{
			\uIf{$\exists q : \zeta[a] \subseteq y_{q}$}{
				$x_{i} \gets positivos_{i}$ \;
			}
			\Else{
				$x_{i} \gets negativos_{i}$ \;
			}
			$i \gets i+1$ \;
		}
		\caption{Algoritmo de generación del conjunto de atributos para una
			instancia sintética}
	\end{algorithm}
\end{center}
% textidote: ignore end

\subsection{Algoritmo de Ensamble}
\label{tecnica_algoritmo_ensamble}

El \acrfull{efmp} es una estrategia de ensamble en ambientes de flujos continuos
que pondera a los clasificadores base de acuerdo a su rendimiento y ajusta los
pesos en cada predicción, a fin de optimizar la exactitud y eficiencia de la
respuesta, y al mismo tiempo mantenerse actualizado frente a los cambios de
concepto. Además es un ensamble que permite definir clasificadores base
modelados a partir de algoritmos de clasificación diferentes para explotar la
variabilidad en los mismos. La técnica de ponderación se basa en la presentada
por \citeauthor{kolter_dynamic_2007} para la estrategia \textit{\acrlong{dwm}}
(\acrshort{dwm}) \cite{kolter_dynamic_2007} y fue ajustada para soportar datos
de múltiples etiquetas. Otra de las cualidades del ensamble \acrshort{dwm} es
que agrega y elimina clasificadores base dinámicamente de acuerdo a su
ponderación. Sin embargo, el costo computacional acarreado es notorio y los
nuevos modelos añadidos son de un mismo tipo y no permite variarlos.  En
consecuencia, se presenta la estrategia \acrshort{efmp} como posible alternativa
junto con una variación del mismo, \acrshort{efmp2}, que muestrea instancias
según la distribución \textit{poisson}. A continuación, se describen ambas
técnicas en detalle.

\acrshort{efmp} mantiene un conjunto fijo de $m$ clasificadores base, cada uno
con un vector de pesos $W_{k} = [w_{0}, w_{1}, \dots, w_{q}]$, donde $1 \leq k
	\leq m$ y $w_{k,j}$ representa el peso del clasificador $k$ para la etiqueta
$j$. En el entrenamiento del modelo se reciben $n$ instancias donde
$n=\left\|D\right\|$ para la estrategia simple. Además se definen los parámetros
$p$, que es la cantidad de instancias observadas entre actualizaciones de los
pesos, y $\beta$, que representa el factor en el que se decrece el peso
$w_{k,j}$ ante cada clasificación errónea. $\beta$ es un valor definido en el
dominio $0 \leq \beta \leq 1$ y toma el valor $0.5$ por defecto. Todos los pesos
son inicializados en 1.

El proceso de aprendizaje se lleva a cabo de la siguiente manera: al arribar una
instancia $i$, \acrshort{efmp} se la asigna a cada uno de los $m$
clasificadores. En primer lugar se realiza la actualización de pesos y si un
clasificador $C_{k}$ no predice correctamente una etiqueta $j$, su peso
$w_{k,j}$ será multiplicado por el factor $\beta$. Luego, se entrena cada
clasificador con la instancia nueva y se repite el procedimiento con la
siguiente. El parámetro $p$ es usado durante esta etapa y determina los períodos
entre los cuales no se deben actualizar los pesos. Una vez completado un período
se normalizan los pesos de manera tal que el máximo peso entre etiquetas es uno.
El algoritmo~\ref{alg:entrenamiento_efmp} presenta el pseudocódigo de este
proceso en detalle.

% textidote: ignore begin
\begin{center}
	\begin{algorithm}[H]
		\label{alg:entrenamiento_efmp}
		\SetAlgoLined
		\DontPrintSemicolon
		\KwIn{
			$\{X,Y\}$: Conjunto de entrenamiento,
			$n$: Número de instancias de entrenamiento,
			$q$: Número de etiquetas,
			$\beta$: Factor de decrecimiento de los pesos,
			$p$: Período entre actualizaciones de los pesos,
			$C$: Clasificadores base,
			$W$: Pesos de los clasificadores
		}
		$i \gets 0$ \;
		$m \gets \left\|C\right\|$ \;
		\While{$i < n$}{
			\If{$i \bmod p = 0$}{
				$k \gets 0$ \;
				\While{$k < m$}{
					$y_{i} \gets predecir(C_{k}, X_{i})$ \;
					$j \gets 0$ \;
					\While{$j < q $}{
						\If{$y_{i, j} \neq Y_{i,j}$}{
							$W_{k,j} \gets \beta * W_{k,j}$ \;
						}
						$j \gets j+1$ \;
					}
					$k \gets k+1$\;
				}
				$W \gets escalarPesos(W)$ \;
			}
			$k \gets 0$ \;
			\While{$k < m$}{
				$entrenar(C_{k}, X_{i}, Y_{i})$ \;
				$k \gets k+1$\;
			}
			$i \gets i+1$\;
		}
		\caption{Algoritmo de entrenamiento y ajuste de pesos para \acrfull{efmp}}
	\end{algorithm}
\end{center}
% textidote: ignore end

Durante la etapa de predicción cada clasificador retorna su voto $v_{i,j,k}$ y
el ensamble realiza la combinación computando la suma ponderada para cada
etiqueta. La ecuación es la siguiente:

\begin{equation}
	y_{i,j} = \frac{1}{\sum_{k=1}^{m} w_{j,k}} \sum_{k=1}^{m} v_{i,j,k} *
	w_{j,k}
\end{equation}

Las etiquetas cuyo valor superen un umbral de $0.5$ serán activadas:

\begin{equation}
	y_{i,j} =
	\begin{cases}
		1, & \text{si}\ y_{i,j} \geq 0.5 \\
		0, & \text{de otro modo.}
	\end{cases}
\end{equation}

\acrshort{efmp2} introduce una única variación, durante el entrenamiento. Cuando
arriba una instancia $i$, cada uno de los clasificador base entrena el modelo
$Poisson(1)$ veces con dicha instancia. Esta técnica es conocida como
\textit{online bagging} y se ha probado que se aproxima a la estrategia
tradicional de \textit{bagging} en \textit{batch}, cuando se entrena con
ejemplos de distribución similar \cite{oza_online_2005}.

\todo[inline]{explicar: como se adaptaron los algoritmos? el script usado para
	entrenar y predecir? los archivos generados con los resultados? }

\todo[inline]{Explicar más sobre el análisis y evaluación de los flujos
	sintéticos??}
